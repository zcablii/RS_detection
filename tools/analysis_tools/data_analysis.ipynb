{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before submission, check box areas are not zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27315\n",
      "27315 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../submit_zips/oriented_rcnn_r101_fpn_1x_dota_ms_with_flip_rotate_balance_cate.csv',header=None) # s2anet_r50_fpn_1x_fair1m_1_5,  oriented_rcnn_r101_fpn_1x_dota_ms_with_flip_rotate_balance_cate\n",
    "df = df.round(3)\n",
    "ct = 0\n",
    "temp_name = ''\n",
    "to_drop = []\n",
    "print(df.shape[0])\n",
    "for i in range(df.shape[0]):\n",
    "    x1,y1 = df.iloc[i,2],df.iloc[i,3]\n",
    "    x2,y2 = df.iloc[i,4],df.iloc[i,5]\n",
    "    x3,y3 = df.iloc[i,6],df.iloc[i,7]\n",
    "    x4,y4 = df.iloc[i,8],df.iloc[i,9]\n",
    "    area = np.sqrt((x1-x2)**2+(y1-y2)**2) * np.sqrt((x3-x2)**2+(y3-y2)**2)\n",
    "    if area == 0:\n",
    "        to_drop.append(i)\n",
    "        # print(i)\n",
    "\n",
    "droped_df = df.drop(to_drop)\n",
    "print(droped_df.shape[0], len(to_drop))\n",
    "droped_df.to_csv('postpocessed.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw BBox on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "if not os.path.exists('../../res_with_box/'):\n",
    "    os.mkdir('../../res_with_box/')\n",
    "\n",
    "if not os.path.exists('../../res_test_gt_vis/'):\n",
    "    os.mkdir('../../res_test_gt_vis/')\n",
    "# gt_color = (0, 0, 0)\n",
    "\n",
    "# gts = np.load('../gts.npy')\n",
    "# gt_df = pd.DataFrame(gts)\n",
    "# gt_df = gt_df.astype({0: int, 1: int, 2: int,3: int,4: int,5: int,6: int,7: int,8: int})\n",
    "\n",
    "# file_names = set(gt_df[0])\n",
    "\n",
    "\n",
    "# # # read image\n",
    "# # ct = 0\n",
    "\n",
    "# for img_name in file_names:\n",
    "#     result = cv2.imread('/opt/data/private/LYX/data/data/test/images/'+str(img_name)+'.tif')\n",
    "#     # print(result)\n",
    "#     gt_img_labels = gt_df[gt_df[0]==img_name].loc[:,1:8]\n",
    "\n",
    "#     for index, row in gt_img_labels.iterrows():\n",
    "     \n",
    "   \n",
    "#         x1,y1 = row[1],row[2]\n",
    "#         x2,y2 = row[3],row[4]\n",
    "#         x3,y3 = row[5],row[6]\n",
    "#         x4,y4 = row[7],row[8]\n",
    "\n",
    "#         cv2.line(result, (x1, y1), (x2, y2), gt_color, 1)\n",
    "#         cv2.line(result, (x2, y2), (x3, y3), gt_color, 1)\n",
    "#         cv2.line(result, (x3, y3), (x4, y4), gt_color, 1)\n",
    "#         cv2.line(result, (x4, y4), (x1, y1), gt_color, 1)\n",
    "\n",
    "#     cv2.imwrite('../../res_test_gt_vis/'+str(img_name)+'.jpg',result) \n",
    "\n",
    "\n",
    "rgb_dict={'Airplane':(70, 240, 240), 'Ship':(0, 0, 128), 'Vehicle':(128, 128, 0), 'Basketball_Court':(255,225,25), 'Tennis_Court':(210, 245, 60), 'Football_Field':(245, 130, 48), 'Baseball_Field':(255, 215, 180), 'Intersection':(60, 180, 75), 'Roundabout':(145, 30, 180), 'Bridge':(220, 190, 255)}\n",
    "\n",
    "df = pd.read_csv('../../submit_zips/orcnn_r152_fpn_ms_flip_rotate_bc_fair_dota_epoch12.csv',header=None) # s2anet_r50_fpn_1x_fair1m_1_5,  oriented_rcnn_r101_fpn_1x_dota_ms_with_flip_rotate_balance_cate\n",
    "df = df.astype({2: int,3: int,4: int,5: int,6: int,7: int,8: int,9: int})\n",
    "# read image\n",
    "ct = 0\n",
    "temp_name = ''\n",
    "for i in range(df.shape[0]):\n",
    "    if df.iloc[i,-1]<0.5:\n",
    "        continue\n",
    "    img_name = df.iloc[i,0]\n",
    "    if temp_name!=img_name:\n",
    "        if len(temp_name)>0:\n",
    "            cv2.imwrite('../../res_with_box/'+img_name[:-3]+'jpg',result) \n",
    "        temp_name = img_name\n",
    "        \n",
    "        result = cv2.imread('../../res_test_gt_vis/'+img_name[:-3]+'jpg')\n",
    "    cls_name = df.iloc[i,1]\n",
    "    cfdc = df.iloc[i,-1]\n",
    "    x1,y1 = df.iloc[i,2],df.iloc[i,3]\n",
    "    x2,y2 = df.iloc[i,4],df.iloc[i,5]\n",
    "    x3,y3 = df.iloc[i,6],df.iloc[i,7]\n",
    "    x4,y4 = df.iloc[i,8],df.iloc[i,9]\n",
    "\n",
    "    colr = rgb_dict[cls_name]\n",
    "\n",
    "    # cv2.line(image, start_point, end_point, color, thickness)\n",
    "    cv2.line(result, (x1, y1), (x2, y2), colr, 1)\n",
    "    cv2.line(result, (x2, y2), (x3, y3), colr, 1)\n",
    "    cv2.line(result, (x3, y3), (x4, y4), colr, 1)\n",
    "    cv2.line(result, (x4, y4), (x1, y1), colr, 1)\n",
    "    # cv2.putText(result,cls_name+' '+str(cfdc),(x1, y1),0,0.4,colr) #cv2.putText(image, 'OpenCV', org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "    \n",
    "    # save resulting image\n",
    "    # cv2.imwrite('../../res_with_box/'+img_name[:-3]+'jpg',result)     \n",
    "    ct+=1\n",
    "    # if ct==10:break\n",
    "# cv2.imshow('window_name', result) \n",
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess FAIR1M2.0 data, remove and rename classes and move files to target folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3290.xml\n",
      "save\n"
     ]
    }
   ],
   "source": [
    "# Bridge Roundabout Intersection Baseball_Field Football_Field Tennis_Court Basketball_Court Vehicle Ship Airplane\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import xml.etree.ElementTree as ET\n",
    "import pprint\n",
    "import shutil\n",
    "pp = pprint.PrettyPrinter(depth=4)\n",
    "\n",
    "jdet_coarse2fine_mappings = {\n",
    "    \"Airplane\": [\n",
    "        \"A220\", \"A321\", \"A330\", \"A350\", \"ARJ21\", \"Boeing737\", \"Boeing747\",\n",
    "        \"Boeing777\", \"Boeing787\", \"C919\", \"other-airplane\"],\n",
    "    \"Ship\": [\n",
    "        \"Tugboat\", \"other-ship\", \"Liquid Cargo Ship\", \"Motorboat\",\n",
    "        \"Passenger Ship\", \"Dry Cargo Ship\", \"Warship\", \"Engineering Ship\",\n",
    "        \"Fishing Boat\"],\n",
    "    \"Vehicle\": [\n",
    "        \"other-vehicle\", \"Bus\", \"Cargo Truck\", \"Small Car\", \"Dump Truck\",\n",
    "        \"Van\", \"Excavator\", \"Tractor\", \"Trailer\", \"Truck Tractor\"],\n",
    "    \"Basketball_Court\": [\"Basketball Court\"],\n",
    "    \"Tennis_Court\": [\"Tennis Court\"],\n",
    "    \"Football_Field\": [\"Football Field\"],\n",
    "    \"Baseball_Field\": [\"Baseball Field\"],\n",
    "    \"Intersection\": [\"Intersection\"],\n",
    "    \"Roundabout\": [\"Roundabout\"],\n",
    "    \"Bridge\": [\"Bridge\"],\n",
    "}\n",
    "\n",
    "\n",
    "data_xml_root = './' # \"/media/data3/lyx/Detection/data/train/labelXml/\"\n",
    "data_img_root = './' # \"/media/data3/lyx/Detection/data/train/images/\"\n",
    "target_xml_root =  'out' #  \"/media/data3/lyx/Detection/merge_data/train/labelXml/\"\n",
    "target_img_root =  'out' #  \"/media/data3/lyx/Detection/merge_data/train/images/\"\n",
    "\n",
    "distributions = dict()\n",
    "total_imgs = 0\n",
    "\n",
    "sub_dir_path = data_xml_root\n",
    "xml_files = [f for f in os.listdir(sub_dir_path)\n",
    "                if osp.isfile(osp.join(sub_dir_path, f))]\n",
    "# print(xml_files)\n",
    "for xml_file in xml_files:\n",
    "    print(xml_file)\n",
    "    if not xml_file.endswith('.xml'):\n",
    "        continue\n",
    "    xml_path = osp.join(sub_dir_path, xml_file)\n",
    "    tree = ET.parse(xml_path)\n",
    "\n",
    "    root = tree.getroot()\n",
    "    if len(root.findall('objects')) != 1:\n",
    "        raise ValueError('xml file {} has more than one objects'.format(xml_file))\n",
    "    objects = root.find('objects')\n",
    "    for obj in objects.findall('object'):\n",
    "        possible_result = obj.find('possibleresult')\n",
    "        cls_name = possible_result.find('name').text\n",
    "\n",
    "        # rename object\n",
    "        found = False\n",
    "        for key, value in jdet_coarse2fine_mappings.items():\n",
    "            if key == cls_name:\n",
    "                found = True\n",
    "            else:\n",
    "                for v in value:\n",
    "                    if v == cls_name:\n",
    "                        possible_result.find('name').text = key\n",
    "                        found = True\n",
    "            \n",
    "        # remove object\n",
    "        if not found:\n",
    "            objects.remove(obj)\n",
    "        \n",
    "    if len(objects)>0:\n",
    "        # print('save')\n",
    "        # tree.write('out.xml')\n",
    "        png_file = xml_file.split('.')[0]+'png'\n",
    "        # tree.write(osp.join(target_xml_root + xml_file))\n",
    "        # shutil.copyfile(data_img_root+png_file, target_img_root + png_file) \n",
    "\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get primary train data information and statistics   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "root = '/media/data3/lyx/Detection/data/train/labelXml'\n",
    "files = sorted(glob.glob(root+ \"/*.*\"))\n",
    "cls_name = []\n",
    "file_name = []\n",
    "x1=[]\n",
    "y1=[]\n",
    "x2=[]\n",
    "y2=[]\n",
    "x3=[]\n",
    "y3=[]\n",
    "x4=[]\n",
    "y4=[]\n",
    "pts_list = []\n",
    "\n",
    "for each_file in files:\n",
    "    with open(each_file, 'r') as f:\n",
    "        data = f.read()\n",
    "    \n",
    "    # Passing the stored data inside\n",
    "    # the beautifulsoup parser, storing\n",
    "    # the returned object\n",
    "    Bs_data = BeautifulSoup(data, \"xml\")\n",
    "    \n",
    "    # Finding all instances of tag\n",
    "    # `unique`\n",
    "    objects = Bs_data.find_all('object')\n",
    "    \n",
    "    objects[0].find_all('point')[0].text\n",
    "\n",
    "    for i in range(len(objects)):\n",
    "        obj = objects[i]\n",
    "        file_name.append(each_file.split('/')[-1])\n",
    "        cls_name.append(obj.find('name').text)\n",
    "        points = obj.find_all('point')\n",
    "        pts = []\n",
    "        for each in points:\n",
    "            pts.append(eval(each.text)[0])\n",
    "            pts.append(eval(each.text)[1])\n",
    "        pts_list.append(pts)\n",
    "\n",
    "pts_list = np.array(pts_list)\n",
    "x1=pts_list[:,0]\n",
    "y1=pts_list[:,1]\n",
    "x2=pts_list[:,2]\n",
    "y2=pts_list[:,3]\n",
    "x3=pts_list[:,4]\n",
    "y3=pts_list[:,5]\n",
    "x4=pts_list[:,6]\n",
    "y4=pts_list[:,7]\n",
    "\n",
    "data = {'name':cls_name,'file':file_name,  'x1':x1,'y1':y1,'x2':x2,'y2':y2,'x3':x3,'y3':y3,'x4':x4,'y4':y4}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('train_set_data.csv',index=False)\n",
    "\n",
    "df['area'] = np.sqrt((df['x1']-df['x2'])**2+(df['y1']-df['y2'])**2) * np.sqrt((df['x3']-df['x2'])**2+(df['y3']-df['y2'])**2)\n",
    "width = np.sqrt((df['x1']-df['x2'])**2+(df['y1']-df['y2'])**2)\n",
    "length = np.sqrt((df['x3']-df['x2'])**2+(df['y3']-df['y2'])**2)\n",
    "for i in range(len(width)):\n",
    "    if width[i] > length[i]:\n",
    "        l = width[i]\n",
    "        width[i] = length[i]\n",
    "        length[i] = l\n",
    "df['width'] = width\n",
    "df['length'] = length\n",
    "df['ratio'] = length/width\n",
    "\n",
    "# normed_area\n",
    "cls_names = []\n",
    "stats = []\n",
    "for n in ['Airplane','Ship', 'Vehicle', 'Basketball Court', 'Tennis Court', 'Football Field', 'Baseball Field', 'Intersection', 'Roundabout', 'Bridge']:\n",
    "    cls_names.append(n)\n",
    "    areas = df[df['name']==n]['area']\n",
    "    mean_area = areas.mean()\n",
    "    normed_var_area= np.var(areas/mean_area)\n",
    "    ratios = df[df['name']==n]['ratio']\n",
    "    mean_ratios= ratios.mean()\n",
    "    normed_var_ratios= np.var(ratios/mean_ratios)\n",
    "    stats.append([len(areas), mean_area, normed_var_area,mean_ratios, normed_var_ratios])\n",
    "stats = np.array(stats)\n",
    "stats_dict = {'name':cls_names, 'amount':stats[:,0],'mean_area':stats[:,1],'normed_var_area':stats[:,2],'mean_ratio':stats[:,3],'normed_var_ratio':stats[:,4]}\n",
    "stats_df = pd.DataFrame(stats_dict)\n",
    "stats_df.to_csv('train_set_stats.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get processed train data information and statistics (Please refer to this statistics)\n",
    "\n",
    "please delete image and txt file of P5877_1.0_976_976 and P5877_1.0_824_976 becase the processed bbox is actually a line without area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [name, file, x1, y1, x2, y2, x3, y3, x4, y4, area, width, length, ratio]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "root = '/media/data3/lyx/Detection/preprocessed_ms/train_1024_200_0.5-1.0-1.5/labelTxt/'\n",
    "# root = '/media/data3/lyx/Detection/preprocessed/train_1024_200_1.0/labelTxt/'\n",
    "files = sorted(glob.glob(root+ \"/*.*\"))\n",
    "cls_name = []\n",
    "file_name = []\n",
    "x1=[]\n",
    "y1=[]\n",
    "x2=[]\n",
    "y2=[]\n",
    "x3=[]\n",
    "y3=[]\n",
    "x4=[]\n",
    "y4=[]\n",
    "pts_list = []\n",
    "\n",
    "for each_file in files:\n",
    "    file1 = open(each_file, 'r')\n",
    "    Lines = file1.readlines()\n",
    "    for line in Lines:\n",
    "        file_name.append(each_file.split('/')[-1])\n",
    "        pts = []\n",
    "        l =line.strip().split(' ')\n",
    "        cls_name.append(l[8])\n",
    "        for i in range(8):\n",
    "            pts.append(eval(l[i]))\n",
    "        pts_list.append(pts)\n",
    "\n",
    "\n",
    "pts_list = np.array(pts_list)\n",
    "x1=pts_list[:,0]\n",
    "y1=pts_list[:,1]\n",
    "x2=pts_list[:,2]\n",
    "y2=pts_list[:,3]\n",
    "x3=pts_list[:,4]\n",
    "y3=pts_list[:,5]\n",
    "x4=pts_list[:,6]\n",
    "y4=pts_list[:,7]\n",
    "\n",
    "data = {'name':cls_name,'file':file_name,  'x1':x1,'y1':y1,'x2':x2,'y2':y2,'x3':x3,'y3':y3,'x4':x4,'y4':y4}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['area'] = np.sqrt((df['x1']-df['x2'])**2+(df['y1']-df['y2'])**2) * np.sqrt((df['x3']-df['x2'])**2+(df['y3']-df['y2'])**2)\n",
    "width = np.sqrt((df['x1']-df['x2'])**2+(df['y1']-df['y2'])**2)\n",
    "length = np.sqrt((df['x3']-df['x2'])**2+(df['y3']-df['y2'])**2)\n",
    "for i in range(len(width)):\n",
    "    if width[i] > length[i]:\n",
    "        l = width[i]\n",
    "        width[i] = length[i]\n",
    "        length[i] = l\n",
    "df['width'] = width\n",
    "df['length'] = length\n",
    "df['ratio'] = length/width\n",
    "thin_box = df.loc[df['area'] == 0]\n",
    "print(thin_box)\n",
    "df.to_csv('train_set_data.csv',index=False)\n",
    "\n",
    "\n",
    "cls_names = []\n",
    "stats = []\n",
    "for n in ['Airplane','Ship', 'Vehicle', 'Basketball_Court', 'Tennis_Court', 'Football_Field', 'Baseball_Field', 'Intersection', 'Roundabout', 'Bridge']:\n",
    "    cls_names.append(n)\n",
    "    areas = df[df['name']==n]['area']\n",
    "    mean_area = areas.mean()\n",
    "    normed_var_area= np.var(areas/mean_area)\n",
    "    ratios = df[df['name']==n]['ratio']\n",
    "    mean_ratios= ratios.mean()\n",
    "    normed_var_ratios= np.var(ratios/mean_ratios)\n",
    "    stats.append([len(areas), mean_area, normed_var_area,mean_ratios, normed_var_ratios])\n",
    "stats = np.array(stats)\n",
    "stats_dict = {'name':cls_names, 'amount':stats[:,0],'mean_area':stats[:,1],'normed_var_area':stats[:,2],'mean_ratio':stats[:,3],'normed_var_ratio':stats[:,4]}\n",
    "stats_df = pd.DataFrame(stats_dict)\n",
    "stats_df.to_csv('train_set_stats.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import inf\n",
    "\n",
    "\n",
    "len(df)\n",
    "thin_box = df.loc[df['area'] == 0]\n",
    "thin_box.to_csv('thin_box.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
